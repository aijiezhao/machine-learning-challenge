{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/zhaoaijie/opt/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/zhaoaijie/opt/anaconda3/lib/python3.7/site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /Users/zhaoaijie/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /Users/zhaoaijie/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/zhaoaijie/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/zhaoaijie/opt/anaconda3/lib/python3.7/site-packages (0.14.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>874.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5455</td>\n",
       "      <td>81</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>31.04</td>\n",
       "      <td>-10.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5853</td>\n",
       "      <td>158</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>33.46</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>668.95</td>\n",
       "      <td>-230.35</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5805</td>\n",
       "      <td>157</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>603.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>874.33</td>\n",
       "      <td>-314.24</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6031</td>\n",
       "      <td>169</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>686.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>420.33</td>\n",
       "      <td>-136.70</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6046</td>\n",
       "      <td>189</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.103633</td>\n",
       "      <td>2.030000e-05</td>\n",
       "      <td>-2.030000e-05</td>\n",
       "      <td>176.948600</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>3.16100</td>\n",
       "      <td>0.06350</td>\n",
       "      <td>-0.06350</td>\n",
       "      <td>887.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>687</td>\n",
       "      <td>52.82</td>\n",
       "      <td>16.30</td>\n",
       "      <td>-14.35</td>\n",
       "      <td>39.3</td>\n",
       "      <td>1</td>\n",
       "      <td>4861</td>\n",
       "      <td>131</td>\n",
       "      <td>-146</td>\n",
       "      <td>4.574</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>283.22141</td>\n",
       "      <td>40.421829</td>\n",
       "      <td>15.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.715108</td>\n",
       "      <td>1.940000e-05</td>\n",
       "      <td>-1.940000e-05</td>\n",
       "      <td>134.961780</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>-0.003240</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>2.50600</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>-0.10300</td>\n",
       "      <td>417.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>823</td>\n",
       "      <td>108.84</td>\n",
       "      <td>33.58</td>\n",
       "      <td>-29.57</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2</td>\n",
       "      <td>4861</td>\n",
       "      <td>131</td>\n",
       "      <td>-146</td>\n",
       "      <td>4.574</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>283.22141</td>\n",
       "      <td>40.421829</td>\n",
       "      <td>15.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.365840</td>\n",
       "      <td>8.060000e-06</td>\n",
       "      <td>-8.060000e-06</td>\n",
       "      <td>171.135750</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>2.97210</td>\n",
       "      <td>0.04080</td>\n",
       "      <td>-0.04080</td>\n",
       "      <td>780.7</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>914</td>\n",
       "      <td>165.33</td>\n",
       "      <td>121.73</td>\n",
       "      <td>-40.81</td>\n",
       "      <td>70.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5776</td>\n",
       "      <td>155</td>\n",
       "      <td>-155</td>\n",
       "      <td>4.554</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.212</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>291.14951</td>\n",
       "      <td>40.420521</td>\n",
       "      <td>15.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.040330</td>\n",
       "      <td>3.370000e-07</td>\n",
       "      <td>-3.370000e-07</td>\n",
       "      <td>169.949011</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>1.84110</td>\n",
       "      <td>0.01680</td>\n",
       "      <td>-0.01680</td>\n",
       "      <td>10859.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>-25.8</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>1021</td>\n",
       "      <td>257.29</td>\n",
       "      <td>86.59</td>\n",
       "      <td>-76.86</td>\n",
       "      <td>568.2</td>\n",
       "      <td>1</td>\n",
       "      <td>5035</td>\n",
       "      <td>151</td>\n",
       "      <td>-151</td>\n",
       "      <td>4.519</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>299.31610</td>\n",
       "      <td>40.822380</td>\n",
       "      <td>15.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.330461</td>\n",
       "      <td>3.980000e-05</td>\n",
       "      <td>-3.980000e-05</td>\n",
       "      <td>153.430310</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>5.17600</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>-0.10200</td>\n",
       "      <td>5073.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>-48.4</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>481</td>\n",
       "      <td>12.61</td>\n",
       "      <td>3.84</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>117.2</td>\n",
       "      <td>1</td>\n",
       "      <td>5251</td>\n",
       "      <td>105</td>\n",
       "      <td>-105</td>\n",
       "      <td>4.581</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>292.23676</td>\n",
       "      <td>41.085880</td>\n",
       "      <td>15.855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0        CONFIRMED              0              0              0   \n",
       "1   FALSE POSITIVE              0              1              0   \n",
       "2   FALSE POSITIVE              0              1              0   \n",
       "3        CONFIRMED              0              0              0   \n",
       "4        CONFIRMED              0              0              0   \n",
       "..             ...            ...            ...            ...   \n",
       "95       CONFIRMED              0              0              0   \n",
       "96       CONFIRMED              0              0              0   \n",
       "97       CONFIRMED              0              0              0   \n",
       "98       CONFIRMED              0              0              0   \n",
       "99       CONFIRMED              0              0              0   \n",
       "\n",
       "    koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0               0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1               0   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2               0    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3               0    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4               0    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "..            ...         ...              ...              ...          ...   \n",
       "95              0    8.103633     2.030000e-05    -2.030000e-05   176.948600   \n",
       "96              0    4.715108     1.940000e-05    -1.940000e-05   134.961780   \n",
       "97              0    6.365840     8.060000e-06    -8.060000e-06   171.135750   \n",
       "98              0    3.040330     3.370000e-07    -3.370000e-07   169.949011   \n",
       "99              0   31.330461     3.980000e-05    -3.980000e-05   153.430310   \n",
       "\n",
       "    koi_time0bk_err1  koi_time0bk_err2  koi_impact  koi_impact_err1  \\\n",
       "0           0.003520         -0.003520       0.586            0.059   \n",
       "1           0.000581         -0.000581       0.969            5.126   \n",
       "2           0.000115         -0.000115       1.276            0.115   \n",
       "3           0.001130         -0.001130       0.701            0.235   \n",
       "4           0.001900         -0.001900       0.762            0.139   \n",
       "..               ...               ...         ...              ...   \n",
       "95          0.002050         -0.002050       0.047            0.409   \n",
       "96          0.003240         -0.003240       0.258            0.195   \n",
       "97          0.001000         -0.001000       0.524            0.009   \n",
       "98          0.000089         -0.000089       0.736            0.013   \n",
       "99          0.001030         -0.001030       0.798            0.021   \n",
       "\n",
       "    koi_impact_err2  koi_duration  koi_duration_err1  koi_duration_err2  \\\n",
       "0            -0.443       4.50700            0.11600           -0.11600   \n",
       "1            -0.077       1.78220            0.03410           -0.03410   \n",
       "2            -0.092       2.40641            0.00537           -0.00537   \n",
       "3            -0.478       1.65450            0.04200           -0.04200   \n",
       "4            -0.532       3.14020            0.06730           -0.06730   \n",
       "..              ...           ...                ...                ...   \n",
       "95           -0.047       3.16100            0.06350           -0.06350   \n",
       "96           -0.258       2.50600            0.10300           -0.10300   \n",
       "97           -0.460       2.97210            0.04080           -0.04080   \n",
       "98           -0.024       1.84110            0.01680           -0.01680   \n",
       "99           -0.043       5.17600            0.10200           -0.10200   \n",
       "\n",
       "    koi_depth  koi_depth_err1  koi_depth_err2  koi_prad  koi_prad_err1  \\\n",
       "0       874.8            35.5           -35.5      2.83           0.32   \n",
       "1     10829.0           171.0          -171.0     14.60           3.92   \n",
       "2      8079.2            12.8           -12.8     33.46           8.50   \n",
       "3       603.3            16.9           -16.9      2.75           0.88   \n",
       "4       686.0            18.7           -18.7      2.77           0.90   \n",
       "..        ...             ...             ...       ...            ...   \n",
       "95      887.9            24.5           -24.5      2.11           0.18   \n",
       "96      417.5            22.0           -22.0      1.46           0.12   \n",
       "97      780.7            13.1           -13.1      2.44           0.60   \n",
       "98    10859.0            25.8           -25.8      8.99           0.80   \n",
       "99     5073.8            48.4           -48.4      6.50           0.64   \n",
       "\n",
       "    koi_prad_err2  koi_teq  koi_insol  koi_insol_err1  koi_insol_err2  \\\n",
       "0           -0.19      443       9.11            2.87           -1.62   \n",
       "1           -1.31      638      39.30           31.04          -10.49   \n",
       "2           -2.83     1395     891.96          668.95         -230.35   \n",
       "3           -0.35     1406     926.16          874.33         -314.24   \n",
       "4           -0.30     1160     427.65          420.33         -136.70   \n",
       "..            ...      ...        ...             ...             ...   \n",
       "95          -0.20      687      52.82           16.30          -14.35   \n",
       "96          -0.14      823     108.84           33.58          -29.57   \n",
       "97          -0.21      914     165.33          121.73          -40.81   \n",
       "98          -0.99     1021     257.29           86.59          -76.86   \n",
       "99          -0.23      481      12.61            3.84           -1.79   \n",
       "\n",
       "    koi_model_snr  koi_tce_plnt_num  koi_steff  koi_steff_err1  \\\n",
       "0            25.8                 2       5455              81   \n",
       "1            76.3                 1       5853             158   \n",
       "2           505.6                 1       5805             157   \n",
       "3            40.9                 1       6031             169   \n",
       "4            40.2                 2       6046             189   \n",
       "..            ...               ...        ...             ...   \n",
       "95           39.3                 1       4861             131   \n",
       "96           21.3                 2       4861             131   \n",
       "97           70.8                 1       5776             155   \n",
       "98          568.2                 1       5035             151   \n",
       "99          117.2                 1       5251             105   \n",
       "\n",
       "    koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
       "0              -81      4.467           0.064          -0.096     0.927   \n",
       "1             -176      4.544           0.044          -0.176     0.868   \n",
       "2             -174      4.564           0.053          -0.168     0.791   \n",
       "3             -211      4.438           0.070          -0.210     1.046   \n",
       "4             -232      4.486           0.054          -0.229     0.972   \n",
       "..             ...        ...             ...             ...       ...   \n",
       "95            -146      4.574           0.054          -0.041     0.732   \n",
       "96            -146      4.574           0.054          -0.041     0.732   \n",
       "97            -155      4.554           0.042          -0.168     0.849   \n",
       "98            -151      4.519           0.084          -0.063     0.791   \n",
       "99            -105      4.581           0.010          -0.085     0.817   \n",
       "\n",
       "    koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0           0.105         -0.061  291.93423  48.141651      15.347  \n",
       "1           0.233         -0.078  297.00482  48.134129      15.436  \n",
       "2           0.201         -0.067  285.53461  48.285210      15.597  \n",
       "3           0.334         -0.133  288.75488  48.226200      15.509  \n",
       "4           0.315         -0.105  296.28613  48.224670      15.714  \n",
       "..            ...            ...        ...        ...         ...  \n",
       "95          0.062         -0.068  283.22141  40.421829      15.289  \n",
       "96          0.062         -0.068  283.22141  40.421829      15.289  \n",
       "97          0.212         -0.071  291.14951  40.420521      15.090  \n",
       "98          0.071         -0.087  299.31610  40.822380      15.028  \n",
       "99          0.080         -0.029  292.23676  41.085880      15.855  \n",
       "\n",
       "[100 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>-0.4430</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>5.1260</td>\n",
       "      <td>-0.0770</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>-0.0920</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>33.46</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-0.4780</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>-0.5320</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.566589</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>179.554370</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>-0.004610</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>-0.5230</td>\n",
       "      <td>2.42900</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>-0.16500</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.068647</td>\n",
       "      <td>1.090000e-05</td>\n",
       "      <td>-1.090000e-05</td>\n",
       "      <td>173.621937</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>-0.0520</td>\n",
       "      <td>3.53470</td>\n",
       "      <td>0.02410</td>\n",
       "      <td>-0.02410</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>286.99948</td>\n",
       "      <td>48.375790</td>\n",
       "      <td>15.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.470613</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>-2.700000e-08</td>\n",
       "      <td>122.763305</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>1.74319</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>-0.00107</td>\n",
       "      <td>13.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>286.80847</td>\n",
       "      <td>49.316399</td>\n",
       "      <td>11.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.204735</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>-4.300000e-08</td>\n",
       "      <td>121.358542</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-0.2160</td>\n",
       "      <td>3.88864</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>-0.00203</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>1.952</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>292.24728</td>\n",
       "      <td>47.969521</td>\n",
       "      <td>10.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.522498</td>\n",
       "      <td>1.980000e-07</td>\n",
       "      <td>-1.980000e-07</td>\n",
       "      <td>121.119423</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>3.19843</td>\n",
       "      <td>0.00653</td>\n",
       "      <td>-0.00653</td>\n",
       "      <td>14.59</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>281.28812</td>\n",
       "      <td>42.451080</td>\n",
       "      <td>13.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.709214</td>\n",
       "      <td>6.540000e-06</td>\n",
       "      <td>-6.540000e-06</td>\n",
       "      <td>133.983180</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>-0.0510</td>\n",
       "      <td>2.63020</td>\n",
       "      <td>0.04270</td>\n",
       "      <td>-0.04270</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>295.64871</td>\n",
       "      <td>48.495560</td>\n",
       "      <td>12.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.521446</td>\n",
       "      <td>1.980000e-06</td>\n",
       "      <td>-1.980000e-06</td>\n",
       "      <td>170.839688</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>2.4830</td>\n",
       "      <td>2.8510</td>\n",
       "      <td>-0.6730</td>\n",
       "      <td>3.63990</td>\n",
       "      <td>0.01140</td>\n",
       "      <td>-0.01140</td>\n",
       "      <td>150.51</td>\n",
       "      <td>39.76</td>\n",
       "      <td>-13.31</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>297.07993</td>\n",
       "      <td>47.597401</td>\n",
       "      <td>15.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.221389</td>\n",
       "      <td>1.120000e-06</td>\n",
       "      <td>-1.120000e-06</td>\n",
       "      <td>184.552164</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>1.0650</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>4.79843</td>\n",
       "      <td>0.00235</td>\n",
       "      <td>-0.00235</td>\n",
       "      <td>49.29</td>\n",
       "      <td>16.03</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>295.81454</td>\n",
       "      <td>47.690350</td>\n",
       "      <td>15.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.469838</td>\n",
       "      <td>1.360000e-05</td>\n",
       "      <td>-1.360000e-05</td>\n",
       "      <td>180.881761</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>-0.1010</td>\n",
       "      <td>9.43780</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>-0.06000</td>\n",
       "      <td>7.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>297.15442</td>\n",
       "      <td>47.668701</td>\n",
       "      <td>15.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.273582</td>\n",
       "      <td>1.040000e-05</td>\n",
       "      <td>-1.040000e-05</td>\n",
       "      <td>173.258155</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.3870</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.3860</td>\n",
       "      <td>3.28750</td>\n",
       "      <td>0.03090</td>\n",
       "      <td>-0.03090</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>288.13824</td>\n",
       "      <td>47.724449</td>\n",
       "      <td>15.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.029303</td>\n",
       "      <td>5.510000e-06</td>\n",
       "      <td>-5.510000e-06</td>\n",
       "      <td>171.602959</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>-0.2580</td>\n",
       "      <td>1.58210</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>-0.03110</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>283.71088</td>\n",
       "      <td>47.863270</td>\n",
       "      <td>15.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.696371</td>\n",
       "      <td>7.530000e-06</td>\n",
       "      <td>-7.530000e-06</td>\n",
       "      <td>170.737690</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>-0.002340</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>-0.0440</td>\n",
       "      <td>3.61290</td>\n",
       "      <td>0.06860</td>\n",
       "      <td>-0.06860</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>283.76547</td>\n",
       "      <td>47.804298</td>\n",
       "      <td>15.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.941052</td>\n",
       "      <td>1.090000e-05</td>\n",
       "      <td>-1.090000e-05</td>\n",
       "      <td>136.086620</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>-0.2260</td>\n",
       "      <td>2.59840</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>-0.07370</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>292.37613</td>\n",
       "      <td>47.880989</td>\n",
       "      <td>15.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>386.603053</td>\n",
       "      <td>1.369000e-04</td>\n",
       "      <td>-1.369000e-04</td>\n",
       "      <td>166.342079</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>-0.0268</td>\n",
       "      <td>6.80570</td>\n",
       "      <td>0.01840</td>\n",
       "      <td>-0.01840</td>\n",
       "      <td>41.50</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>292.27374</td>\n",
       "      <td>37.671558</td>\n",
       "      <td>12.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.676992</td>\n",
       "      <td>7.010000e-05</td>\n",
       "      <td>-7.010000e-05</td>\n",
       "      <td>171.535940</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>-0.6630</td>\n",
       "      <td>3.45550</td>\n",
       "      <td>0.06560</td>\n",
       "      <td>-0.06560</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>290.46512</td>\n",
       "      <td>47.929180</td>\n",
       "      <td>15.377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0    54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1    19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2     1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3     2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4     4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "5     2.566589     1.780000e-05    -1.780000e-05   179.554370   \n",
       "6    16.068647     1.090000e-05    -1.090000e-05   173.621937   \n",
       "7     2.470613     2.700000e-08    -2.700000e-08   122.763305   \n",
       "8     2.204735     4.300000e-08    -4.300000e-08   121.358542   \n",
       "9     3.522498     1.980000e-07    -1.980000e-07   121.119423   \n",
       "10    3.709214     6.540000e-06    -6.540000e-06   133.983180   \n",
       "11   11.521446     1.980000e-06    -1.980000e-06   170.839688   \n",
       "12   19.221389     1.120000e-06    -1.120000e-06   184.552164   \n",
       "13   16.469838     1.360000e-05    -1.360000e-05   180.881761   \n",
       "14    9.273582     1.040000e-05    -1.040000e-05   173.258155   \n",
       "15    6.029303     5.510000e-06    -5.510000e-06   171.602959   \n",
       "16    2.696371     7.530000e-06    -7.530000e-06   170.737690   \n",
       "17    3.941052     1.090000e-05    -1.090000e-05   136.086620   \n",
       "18  386.603053     1.369000e-04    -1.369000e-04   166.342079   \n",
       "19   21.676992     7.010000e-05    -7.010000e-05   171.535940   \n",
       "\n",
       "    koi_time0bk_err1  koi_time0bk_err2  koi_impact  koi_impact_err1  \\\n",
       "0           0.003520         -0.003520      0.5860           0.0590   \n",
       "1           0.000581         -0.000581      0.9690           5.1260   \n",
       "2           0.000115         -0.000115      1.2760           0.1150   \n",
       "3           0.001130         -0.001130      0.7010           0.2350   \n",
       "4           0.001900         -0.001900      0.7620           0.1390   \n",
       "5           0.004610         -0.004610      0.7550           0.2120   \n",
       "6           0.000517         -0.000517      0.0520           0.2620   \n",
       "7           0.000009         -0.000009      0.8180           0.0010   \n",
       "8           0.000016         -0.000016      0.2240           0.1590   \n",
       "9           0.000047         -0.000047      0.6310           0.0070   \n",
       "10          0.001430         -0.001430      0.0510           0.3950   \n",
       "11          0.000131         -0.000131      2.4830           2.8510   \n",
       "12          0.000045         -0.000045      1.0650           0.0310   \n",
       "13          0.000623         -0.000623      0.2920           0.1180   \n",
       "14          0.000877         -0.000877      0.3870           0.0040   \n",
       "15          0.000713         -0.000713      0.2580           0.1960   \n",
       "16          0.002340         -0.002340      0.0440           0.3600   \n",
       "17          0.002330         -0.002330      0.2260           0.2430   \n",
       "18          0.000299         -0.000299      0.9765           0.0497   \n",
       "19          0.002580         -0.002580      0.8960           0.0100   \n",
       "\n",
       "    koi_impact_err2  koi_duration  koi_duration_err1  koi_duration_err2  \\\n",
       "0           -0.4430       4.50700            0.11600           -0.11600   \n",
       "1           -0.0770       1.78220            0.03410           -0.03410   \n",
       "2           -0.0920       2.40641            0.00537           -0.00537   \n",
       "3           -0.4780       1.65450            0.04200           -0.04200   \n",
       "4           -0.5320       3.14020            0.06730           -0.06730   \n",
       "5           -0.5230       2.42900            0.16500           -0.16500   \n",
       "6           -0.0520       3.53470            0.02410           -0.02410   \n",
       "7           -0.0010       1.74319            0.00107           -0.00107   \n",
       "8           -0.2160       3.88864            0.00203           -0.00203   \n",
       "9           -0.0070       3.19843            0.00653           -0.00653   \n",
       "10          -0.0510       2.63020            0.04270           -0.04270   \n",
       "11          -0.6730       3.63990            0.01140           -0.01140   \n",
       "12          -0.0340       4.79843            0.00235           -0.00235   \n",
       "13          -0.1010       9.43780            0.06000           -0.06000   \n",
       "14          -0.3860       3.28750            0.03090           -0.03090   \n",
       "15          -0.2580       1.58210            0.03110           -0.03110   \n",
       "16          -0.0440       3.61290            0.06860           -0.06860   \n",
       "17          -0.2260       2.59840            0.07370           -0.07370   \n",
       "18          -0.0268       6.80570            0.01840           -0.01840   \n",
       "19          -0.6630       3.45550            0.06560           -0.06560   \n",
       "\n",
       "    koi_prad  koi_prad_err1  koi_prad_err2  koi_srad  koi_srad_err1  \\\n",
       "0       2.83           0.32          -0.19     0.927          0.105   \n",
       "1      14.60           3.92          -1.31     0.868          0.233   \n",
       "2      33.46           8.50          -2.83     0.791          0.201   \n",
       "3       2.75           0.88          -0.35     1.046          0.334   \n",
       "4       2.77           0.90          -0.30     0.972          0.315   \n",
       "5       1.59           0.52          -0.17     0.972          0.315   \n",
       "6       5.76           0.22          -0.49     0.848          0.033   \n",
       "7      13.04           0.51          -0.51     0.964          0.038   \n",
       "8      16.10           0.81          -0.91     1.952          0.099   \n",
       "9      14.59           1.11          -1.11     1.451          0.110   \n",
       "10      1.16           0.17          -0.12     1.022          0.143   \n",
       "11    150.51          39.76         -13.31     0.848          0.224   \n",
       "12     49.29          16.03          -5.00     0.947          0.308   \n",
       "13      7.94           0.89          -0.89     0.786          0.088   \n",
       "14      2.47           0.20          -0.24     0.696          0.056   \n",
       "15      2.85           0.26          -0.15     0.672          0.062   \n",
       "16      1.58           0.13          -0.16     0.819          0.067   \n",
       "17      1.70           0.11          -0.16     0.910          0.057   \n",
       "18     41.50           1.68          -1.68     1.580          0.064   \n",
       "19      2.95           0.12          -0.23     0.828          0.032   \n",
       "\n",
       "    koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0          -0.061  291.93423  48.141651      15.347  \n",
       "1          -0.078  297.00482  48.134129      15.436  \n",
       "2          -0.067  285.53461  48.285210      15.597  \n",
       "3          -0.133  288.75488  48.226200      15.509  \n",
       "4          -0.105  296.28613  48.224670      15.714  \n",
       "5          -0.105  296.28613  48.224670      15.714  \n",
       "6          -0.072  286.99948  48.375790      15.841  \n",
       "7          -0.038  286.80847  49.316399      11.338  \n",
       "8          -0.110  292.24728  47.969521      10.463  \n",
       "9          -0.110  281.28812  42.451080      13.563  \n",
       "10         -0.107  295.64871  48.495560      12.772  \n",
       "11         -0.075  297.07993  47.597401      15.472  \n",
       "12         -0.096  295.81454  47.690350      15.341  \n",
       "13         -0.088  297.15442  47.668701      15.788  \n",
       "14         -0.068  288.13824  47.724449      15.302  \n",
       "15         -0.036  283.71088  47.863270      15.784  \n",
       "16         -0.082  283.76547  47.804298      15.269  \n",
       "17         -0.086  292.37613  47.880989      15.416  \n",
       "18         -0.064  292.27374  37.671558      12.394  \n",
       "19         -0.065  290.46512  47.929180      15.377  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. That will be used as your x values.\n",
    "selected_features = df[[\n",
    "                        'koi_period','koi_period_err1','koi_period_err2',\n",
    "                        'koi_time0bk','koi_time0bk_err1','koi_time0bk_err2',\n",
    "                        'koi_impact','koi_impact_err1','koi_impact_err2',\n",
    "                        'koi_duration','koi_duration_err1','koi_duration_err2',\n",
    "                        'koi_prad','koi_prad_err1','koi_prad_err2',\n",
    "                        'koi_srad','koi_srad_err1','koi_srad_err2',\n",
    "                        'ra','dec','koi_kepmag']]\n",
    "selected_features.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = df[\"koi_disposition\"]\n",
    "X = selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train and test values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 ... 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,StandardScaler\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# scale the data with StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data and make predictions\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.887659736791913\n",
      "Testing Data Score: 0.8895881006864989\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     confirmed       0.85      0.69      0.76       422\n",
      "false positive       0.75      0.87      0.80       450\n",
      "     candidate       0.99      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.89      1748\n",
      "     macro avg       0.86      0.85      0.85      1748\n",
      "  weighted avg       0.89      0.89      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions,\n",
    "                           target_names =[\"confirmed\", \"false positive\", \"candidate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [10, 50, 100],\n",
    "             'max_iter':[200, 500, 1000]}\n",
    "grid = GridSearchCV(model,param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=10, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, max_iter=200, score=0.886, total=   0.2s\n",
      "[CV] C=10, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, max_iter=200, score=0.884, total=   0.2s\n",
      "[CV] C=10, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, max_iter=200, score=0.883, total=   0.2s\n",
      "[CV] C=10, max_iter=200 ..............................................\n",
      "[CV] .................. C=10, max_iter=200, score=0.899, total=   0.2s\n",
      "[CV] C=10, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, max_iter=200, score=0.871, total=   0.2s\n",
      "[CV] C=10, max_iter=500 ..............................................\n",
      "[CV] .................. C=10, max_iter=500, score=0.886, total=   0.4s\n",
      "[CV] C=10, max_iter=500 ..............................................\n",
      "[CV] .................. C=10, max_iter=500, score=0.884, total=   0.3s\n",
      "[CV] C=10, max_iter=500 ..............................................\n",
      "[CV] .................. C=10, max_iter=500, score=0.883, total=   0.3s\n",
      "[CV] C=10, max_iter=500 ..............................................\n",
      "[CV] .................. C=10, max_iter=500, score=0.899, total=   0.3s\n",
      "[CV] C=10, max_iter=500 ..............................................\n",
      "[CV] .................. C=10, max_iter=500, score=0.871, total=   0.3s\n",
      "[CV] C=10, max_iter=1000 .............................................\n",
      "[CV] ................. C=10, max_iter=1000, score=0.886, total=   0.3s\n",
      "[CV] C=10, max_iter=1000 .............................................\n",
      "[CV] ................. C=10, max_iter=1000, score=0.884, total=   0.3s\n",
      "[CV] C=10, max_iter=1000 .............................................\n",
      "[CV] ................. C=10, max_iter=1000, score=0.883, total=   0.3s\n",
      "[CV] C=10, max_iter=1000 .............................................\n",
      "[CV] ................. C=10, max_iter=1000, score=0.899, total=   0.3s\n",
      "[CV] C=10, max_iter=1000 .............................................\n",
      "[CV] ................. C=10, max_iter=1000, score=0.871, total=   0.3s\n",
      "[CV] C=50, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=200, score=0.886, total=   0.3s\n",
      "[CV] C=50, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=200, score=0.883, total=   0.2s\n",
      "[CV] C=50, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=200, score=0.884, total=   0.2s\n",
      "[CV] C=50, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=200, score=0.897, total=   0.2s\n",
      "[CV] C=50, max_iter=200 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=200, score=0.871, total=   0.2s\n",
      "[CV] C=50, max_iter=500 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=500, score=0.885, total=   0.6s\n",
      "[CV] C=50, max_iter=500 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=500, score=0.883, total=   0.5s\n",
      "[CV] C=50, max_iter=500 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=500, score=0.883, total=   0.5s\n",
      "[CV] C=50, max_iter=500 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=500, score=0.896, total=   0.5s\n",
      "[CV] C=50, max_iter=500 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, max_iter=500, score=0.875, total=   0.5s\n",
      "[CV] C=50, max_iter=1000 .............................................\n",
      "[CV] ................. C=50, max_iter=1000, score=0.885, total=   0.6s\n",
      "[CV] C=50, max_iter=1000 .............................................\n",
      "[CV] ................. C=50, max_iter=1000, score=0.883, total=   0.5s\n",
      "[CV] C=50, max_iter=1000 .............................................\n",
      "[CV] ................. C=50, max_iter=1000, score=0.883, total=   0.7s\n",
      "[CV] C=50, max_iter=1000 .............................................\n",
      "[CV] ................. C=50, max_iter=1000, score=0.896, total=   0.6s\n",
      "[CV] C=50, max_iter=1000 .............................................\n",
      "[CV] ................. C=50, max_iter=1000, score=0.874, total=   0.6s\n",
      "[CV] C=100, max_iter=200 .............................................\n",
      "[CV] ................. C=100, max_iter=200, score=0.886, total=   0.2s\n",
      "[CV] C=100, max_iter=200 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=200, score=0.883, total=   0.2s\n",
      "[CV] C=100, max_iter=200 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=200, score=0.882, total=   0.2s\n",
      "[CV] C=100, max_iter=200 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=200, score=0.896, total=   0.3s\n",
      "[CV] C=100, max_iter=200 .............................................\n",
      "[CV] ................. C=100, max_iter=200, score=0.873, total=   0.2s\n",
      "[CV] C=100, max_iter=500 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=500, score=0.884, total=   0.5s\n",
      "[CV] C=100, max_iter=500 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=500, score=0.883, total=   0.5s\n",
      "[CV] C=100, max_iter=500 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=500, score=0.883, total=   0.5s\n",
      "[CV] C=100, max_iter=500 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=500, score=0.896, total=   0.5s\n",
      "[CV] C=100, max_iter=500 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, max_iter=500, score=0.875, total=   0.5s\n",
      "[CV] C=100, max_iter=1000 ............................................\n",
      "[CV] ................ C=100, max_iter=1000, score=0.884, total=   0.8s\n",
      "[CV] C=100, max_iter=1000 ............................................\n",
      "[CV] ................ C=100, max_iter=1000, score=0.883, total=   1.3s\n",
      "[CV] C=100, max_iter=1000 ............................................\n",
      "[CV] ................ C=100, max_iter=1000, score=0.882, total=   0.7s\n",
      "[CV] C=100, max_iter=1000 ............................................\n",
      "[CV] ................ C=100, max_iter=1000, score=0.896, total=   0.7s\n",
      "[CV] C=100, max_iter=1000 ............................................\n",
      "[CV] ................ C=100, max_iter=1000, score=0.875, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   18.8s finished\n",
      "/Users/nadiregokcehan/anaconda3/envs/pythondata/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [10, 50, 100], 'max_iter': [200, 500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'max_iter': 200}\n",
      "0.88441754779179\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistig_reg_model.sav']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "import joblib\n",
    "filename = 'logistig_reg_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
